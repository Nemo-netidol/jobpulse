{"timestamp":"2026-01-28T08:03:07.400962Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-01-28T08:03:07.401476Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/daily_job_scraper.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-28T08:03:07.686871Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/daily_job_scraper.py","lineno":2,"logger":"py.warnings"}
{"timestamp":"2026-01-28T08:03:07.697569Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.698546Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.699347Z","level":"info","event":"Current task name:scrape_remoteOK","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.699573Z","level":"info","event":"Dag name:daily_job_scraper","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.699653Z","level":"info","event":"Starting RemoteOK scrape...","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.896608Z","level":"info","event":"Fetched 100 raw jobs from RemoteOK","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.898850Z","level":"info","event":"Error processing job: 2 validation errors for Job","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.898974Z","level":"info","event":"description","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.899063Z","level":"info","event":"  String should have at least 10 characters [type=string_too_short, input_value='', input_type=str]","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.899211Z","level":"info","event":"    For further information visit https://errors.pydantic.dev/2.12/v/string_too_short","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.899317Z","level":"info","event":"url","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.899383Z","level":"info","event":"  Input should be a valid URL, input is empty [type=url_parsing, input_value='', input_type=str]","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.899424Z","level":"info","event":"    For further information visit https://errors.pydantic.dev/2.12/v/url_parsing","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.904520Z","level":"info","event":"Successfully stored 99/100 RemoteOK jobs","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.904694Z","level":"info","event":"Done. Returned value was: 99","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator","filename":"python.py","lineno":216}
{"timestamp":"2026-01-28T08:03:07.904874Z","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019c03a0-a75a-7a6d-b384-8fb49f97b5d9'), task_id='scrape_remoteOK', dag_id='daily_job_scraper', run_id='manual__2026-01-28T08:03:00+00:00', try_number=1, dag_version_id=UUID('019c039b-c90a-767d-b093-39b305da3a33'), map_index=-1, hostname='fc6294cec41b', context_carrier={}, task=<Task(PythonOperator): scrape_remoteOK>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=2, start_date=datetime.datetime(2026, 1, 28, 8, 3, 7, 200644, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task","filename":"task_runner.py","lineno":1450}
{"timestamp":"2026-01-28T08:03:07.922648Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.924096Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2026-01-28T08:03:07.924180Z","level":"info","event":"Task operator:<Task(PythonOperator): scrape_remoteOK>","logger":"task.stdout"}
